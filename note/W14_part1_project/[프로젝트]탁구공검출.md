# 프로젝트
> 자이카에 장착된 카메라를 이용하여 탁구공을 검출하는 프로젝트 진행
+ RGB 카메라로부터 입력된 이미지에 존재하는 탁구공을 검출한다.
  + 수집, 처리, 학습(증강), 인퍼런스
+ 실체 위치를 추정한다. 
  + Calibration, Sensor Fusion, location estimation
+ 2D 지도에 탁구공의 위치를 표시한다.

# PipeLine
> 카메라로부터 이미지를 입력 받는다 
+ OpenCV 사용
+ 데이터를 준비하고 처리하는 단계
  + 레이블링
  + 왜곡 보정
+ 탁구공 인식 모델 (YOLO 사용)
+ extrinsic 카메라 조정이 필요하다. (탁구공의 위치를 추정한다.)
  + 올바른 거리 추정을 하고 있는 지 확인

# Guide Line
## Data Collection
1. 자이카에 장착된 카메라를 사용해 탁구공 이미지를 촬영한다.
2. 연속된 이미지를 적절한 시간 간격으로 이미지를 추출한다. 
3. 데이터 라벨링을 위해 별도 디렉토리에 저장한다.
## Model Training
4. 모델 학습을 수행
5. 모델 학습의 튜닝 포이튼를 조절하며 학습을 실험
   + Training Hyper-Parameter 조정
   + More Training Dataset & Data Augmentation
6. 학습 결과를 지켜보며, 학습이 잘 진행되고 있는 지 확인

## Model Inference
1. 학습 그래프의 추이를 확인하며, 적절한 모델 파일을 선택한다. 
2. 비디오 데이터를 입력으로 하는 model inference 코드를 작성한다. 
3. 실제 자이카 환경에서 동작 가능한 model inference 코드를 작성한다.
   + Model Inference FPS
   + Model Prediction Accuracy

+ pytorch code -> ONNX(엔진파일을 별도로 생성) -> tensorrt

## Object Position Estimation
1. 탁구공의 실제 지름을 측정한다. 
2. Model의 예측 결과 중에서 활용 가능한 정보를 선택한다. 
3. 자신만의 객체 위치 추정 알고리즘을 작성
4. 실제 자이카에서 실험 결과를 비교 분석한다. 

# 프로젝트 결론
+ 모델 학습 측면에서
  + Fine-Tunning for Hyper-paramater
  + More Training Dataset
  + Anothre Object Dection Model
+ 고성능 컴퓨터에서 충분히 빠른 속도로 동작하던 모델이 자이카에서는 결과가 어떤가?
  + Model Quntization
  + Model Acceleration
+ 장애물의 위치를 최대한 정확히 추정 가능한지?
+ 시간에 따라 장애물의 위치 추정한다면 장애물의 속도와 가속도를 추정가능할지?
+ 장애물의 5초뒤 예상되는 위치는 어딘지 계산할 수 있는지
  + Vision Geometry
  + LiDAR
  + Sensor Fusion
